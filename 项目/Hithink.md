# chatbot 问答方案



## 项目背景

同花顺ifind终端（一般提供给B端的研究员用）在使用终端，希望有一个统一的对话入口，可以查询数据，表格，连接客服等，我们通过chatbot整合了这些功能。

## 基于workflow的方案

**流程： 用户输入 -> 问句消歧（针对多轮问句） -> 模型规划  -> 反思 -> 正文生成**

1. 问句消岐

​		输入： 用户历史问句 + 历史回答  -> 完整问句。

​        细节：用户问的问题可能和前面提问相关，会省略掉主体（之前说了公司名，后面用代词），时间等信息，或者针对上一轮答案，继续追问（例如，上一次用户提问，xxx公司买入点位是多少？第二次再提问：你这个xx毛利润为什么这么低，行业平均是多少？再和市场其它公司对比一下）。对于这种有指代关系的问句，需要先做一次改写，补充相关的背景信息后得到完整问句（xxx公司的毛利率是xxx，行业平均是多少？再和市场其它公司对比一下），之后再去走工作流。

​     	数据合成：qwen-72B合成  + gpt筛选、人工校对（qwen72改写后，先让模型判断改写是否正确和判断理由，确实有歧义的让人校对）

-   历史上下文处理


​       尝试多种策略：历史问句全保留，尝试直接对所有答案进行压缩，单容易丢失信息，导致改写不准确。后续改成只保留最近3轮完整问答（改写后的），前面答案摘要成多个bullet points。

​	**问1：**为什么不考虑澄清？

​    **答1：**看到回答完全不对，用户提前终止，重新提问。如果再加一个澄清的链路，模型有容易过度澄清的倾向（一定要上下文很全才肯回答）



2. 模型规划

   i. 意图识别。

   ii. 分析框架使用。



3. 反思



4. 正文生成

**数据合成**

1. 用户query合成

   为了模型sft的效果，query要多样，需要选择不同类型的query合成数据。从两个维度考虑：意图，难度。

   流程：真实query -> 意图分解 ()

# 类o3，基于REACT的deep research方案

两个需求驱动改进：1.现有workflow流程比较死板。对于有些简单问题规划太复杂，而对于困难问题只能思考一次+反思，深度和广度都不够，无法处理复杂多跳问题。2. 产品想要增加宽基生成策略的功能，现有workflow框架没有代码生成和执行无法解决。例如：将A股市值前五的车企公司和美股市值前10的车企，做成一个ETF，假设分别以4：6的比例投资，每个市场的公司均等持仓。我从去年7月份一次性投入10w，现在收益率是多少，面临多大回撤？

本方案重点解决deep research核心两个问题:  （1）规划短思考 （2）记忆管理

**项目流程：规划收集信息 -> 回答。**

亮点：类o3的短思考+工具调用。引入MCP标准化工具调用方式，加上记忆管理方法，可以实现15+轮次的思考+工具调用。引入代码工具，可以对数据进行计算，以及实现**图文混排**。

#### 1. 规划思考

i. **标准化工具调用**

- 之前的问题：工具描述，参数，任务描述都放在一个prompt里面，管理混乱，无法适配现在MCP接入方式。
- 改进：所有工具标准化openai的调用格式，传入tool里面，后续参考qwen-agent统一为mcp调度。为了做到完全的工具调用，把think，finish也做成了工具，如果是简单问题（）会直接调用finish工具。，代码工具；将搜索引擎工具拆分为search，fetch（后续说明原因）。

ii.  **高效规划**： 

- 之前的问题： 大多数推理模型，deepseek，qwq等思考过程太长，一个简单的查指标问题也要分析一大段，而且中途调用工具还会反复犹豫，耗时太长且给用户展示的效果很差。
- 改进方式：使用最强的推理模型o3生成短思考+工具调用的REACT过程。但是o3有反扒机制，不会输出中间的思考过程，即使在加了think工具后，模型不能保证每次都稳定调用，这样模型一直在调用工具，但是用户不知道模型的推理过程。我们的解决方法是，在每个工具都额外添加一个参数，这个参数描述是模型想调用工具这个工具干什么。

iii. **python解释器**

- 之前的问题：取数工具是一个综合的接口，公司做的不是很好，一个问句会出来很多相关，不相关的表格（例子，xxxx），我们用字符串填充到tool call的message里面表格又多又长，需要做截断。但是取的数据（尤其是一个时间序列的）被截断之后，模型无法对结构化的数据做分析计算（举个例子，~~xx公司股价最高的三天有规律吗，~~），并且生成答案的时候，如果要画图不能画时间序列太长的图。（xx公司近5年的成长曲线是什么样的，用折线图展示公盈利能力，股票价格变化趋势）
- 改进方式：引入python代码解释器工具。1. 把取出来的数据全部转为dataframe对象，按照 sheet_1 :  df.head() + df.tail()  + df.info() 这种格式组织dataframe，模型可以看到这个dataframe前面几行，后面几行是什么，另外也知道各个shema是什么格式（字符串，float），每个shema有多少数据为空。同时在prompt中告诉模型，可以直接引用变量进行操作。2. 用ipython内核执行代码，工具返回的是stdout，traceback等关键信息。 3. 采用函数式编程方式，让模型每次生成单个功能的函数，然后打印函数执行的结果。这样可以避免模型生成一大串代码，但是代码中间其实已经报错了。（dataframe经常有空值，另外dataframe日期格式不统一，2025/7/27，20250207，2025-02-07，需要模型写代码先转换）

iv.**分层记忆管理**

亮点：三级记忆压缩。

- tool级别信息压缩。取数工具输出太长改成dataframe，显著压缩效率。搜索素材太长，把搜索工具拆分为search和fetch。search工具得到结果之后，只会返回的是 id、时间、标题、摘要。如果模型要看全文，需要使用fetch工具，传入文章id，之后可以拿到全文。对于一些无用的网页信息，模型通过标题+摘要就能筛选掉，而如果是干货比较多的，可以进一步查看细节。
- step级别信息压缩。之前的问题：搜索接口不稳定/代码执行出错，模型反复调用工具，规划思考轮数太多，导致上下文超长。（例如，模型多次修改代码得到可以正常运行的代码之后，模型在下一轮规划其实没必要带上之前的上下文，只需要保留正确的代码就行）。step级别压缩是指，如果到达70%的上下文阈值，会对中间的工具调用过程进行删除。（其实可以参考openhands，不仅仅是删除，还会进行摘要。）

- conversation级别压缩。之前的问题：workflow额外引入了一个问句改写功能。改进：直接把用户的历史问句+答案保存到message里面，只保留最近三轮的完整对话记录（last-3 conversation），再之前的会对答案进行摘要，（问句比较短，仍然保留），最多支持10轮对话。

  

  问1：为什么tool级别不用rag，或者embedding召回方法？

  答1：embedding方法对网页来说效果不好，有几个重大缺陷。a. 网页如果太长，需要chunk然后和搜索query做embedding匹配加rerank，效率太低，对于问答系统来说无法承受。b. 有些抽象的概念很难和正文匹配。（例如，xx公司现在值得买吗？如果把这个和正文匹配，很容易得到一些所谓自媒体发布的推广。但其实，如果保留正文中的一些新闻消息，模型可以自己生成观点分析）

#### 2.答案生成

直接把搜索到的dataframe，搜索结果，python执行记录拼在一个prompt。模型按markdown格式生成正文。如果需要画图，采用这种格式<figure> ```python 画图代码块````</figure>。画图工具采用ploty，可以生成交互的图，生成完之后执行代码运行。表格直接引用，dataframe，后台解析到替换成表格组件。

### 端到端强化学习

问1：**为什么没有用端到端RL？**

答1：公司接口不太支持，训练集群无法调用搜索，取数接口，尤其是取数还有并发限制。

问2：如果要用端到端RL做deepresearch，要怎么设计整个训练流程，数据合成怎么做？

答2：xxx

## 其它

#### prompt怎么写？

有以下几个注意点：

- 格式化输出，最好用json或者xml。模型输出这个结构化数据比较容易，也好解析。如果格式出错可以用正则匹配。例如，模型生成工具列表： 1. report: xx 公司研报 2.search：xx新闻。这种多了需要解析的时候考虑把无关的去除。
- few-shot。只在关键的地方写，比如在智能query生成的时候，可以给几个例子帮助模型理解。举例子的时候最好格式多样一些！而不是统一的模板，例如模型的thought部分太简单，可以写几个good例子，告诉模型对于复杂问题，可以先仔细分析需要哪些信息，再做规划，而不是直接把问题扔到搜索工具中。再写一个badcase，告诉模型如果是简单的（查询今天天气，不要写一大串思考内容）。另外，格式之类的（1，（一））这种可以混用，没必要非要统一。另外生成答案的prompt，可以多准备几套，混合着用。
- 注意利用kv-cache。尽量把system做成固定的，可以变的部分，例如时间，用户问题放在后面。这样对不同的问题，可以复用kv-cache。

#### 后续改进

- 转为multi-agent方案。难点是agent之间的通信，可以类似qwen-agent分配任务，或者openhands基于时间驱动，消息订阅。最好多看看代码生成这一块，生成代码是一个比较复杂的任务，需要有很强的记忆管理：  1. 要读取代码目录，输入不会短 2. 要生成代码，cursor一次性创建多个文件，输出也长 3. 用户经常会有很复杂的需求，需要交轮次多。

- 尝试GRPO应用到答案生成，难点是评价答案的好坏，可以参考BRPO。
